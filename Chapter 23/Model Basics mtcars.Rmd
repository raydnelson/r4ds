---
title: "Model Basics mtcars"
author: "MPA 634: Data Science for Managers"
date: "20 November 2019"
output: 
  html_document:
    code_folding: "hide"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE,
                      warning = FALSE,
                      message = FALSE)
# Load libraries
library(tidyverse)
library(car)
```  

## Models

1. Become familiar with the data using graphs
1. Identify families of models that might be appropriate
1. Estimate the models
1. Check the residuals to see if information remains
1. Achieve balance between explanatory power and simplicity 
1. Use the model to make forecasts
 

## Patterns and models (From Chapter 7.6)

> If you spot a pattern, ask yourself:  

> *  Could this pattern be due to coincidence (i.e. random chance)?
> *  How can you describe the relationship implied by the pattern
> *  How strong is the relationship implied by the pattern?
> *  What other variables might affect the relationship?
> *  Does the relationship change if you look at individual subgroups of the data?  

## mtcars: A Simple Regression  

We would like to be able to predict a car's mileage based on its weight.  

### Start with a graph of the data  

```{r graph of mpg on weight}
mtcars %>% 
  ggplot(aes(wt, mpg)) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_smooth(color = "red")
```  

### Estimate a simple regression equation  

```{r simple regression estimation}
mtcars_lm <- lm(mpg ~ wt, data = mtcars)
mtcars_lm %>% str()
mtcars_lm %>% coefficients()
mtcars_lm %>% residuals()
mtcars_lm %>% fitted()
```  

```{r how good is the model from scratch}
estimated_model_data <-  mtcars %>% 
  select(mpg, wt) %>% 
  mutate(
    estimated_values = mtcars_lm %>% fitted(),
    estimated_residuals = mtcars_lm %>% residuals(),
    studentized_residuals = estimated_residuals %>% scale()
  )

estimated_model_data

estimated_model_data %>% 
  ggplot(aes(estimated_values, studentized_residuals)) +
  geom_point() +
  geom_smooth(span = 0.9)

estimated_model_data %>% 
  filter(abs(studentized_residuals) > 2)
```

### How good is the model using the car library?

```{r simple regression model evaluation}
## How good is the model
mtcars_lm %>%
  summary()
mtcars_lm %>% 
  residualPlots()
```  

### Linear model predictions  

```{r mtcars predictions}
## Prediction with the linear model
mtcars_lm %>%
  predict(newdata = tibble(wt = 2))
```  


#### Function to predict

```{r function to make predictions}
predict_cars_lm <- function(x){
  mtcars_lm %>% predict(newdata = tibble(wt = x))
}

predict_cars_lm(5)
mtcars$wt %>% range()
```

## loess model to handle the nonlinear relationship

loess is also known as local regression and is related to the family of generalized additive models

```{r loess model}
mtcars_loess <- loess(mpg ~ wt, data = mtcars)
mtcars_loess %>% str()
```  

### How good is the model?

```{r evaluation of loess model}
mtcars_loess %>% summary()

estimated_model_data <-  mtcars %>% 
  select(mpg, wt) %>% 
  mutate(
    estimated_values = mtcars_loess %>% fitted(),
    estimated_residuals = mtcars_loess %>% residuals(),
    studentized_residuals = estimated_residuals %>% scale()
  )

estimated_model_data

estimated_model_data %>% 
  ggplot(aes(estimated_values, studentized_residuals)) +
  geom_point() +
  geom_smooth(span = 0.9)

estimated_model_data %>% 
  filter(abs(studentized_residuals) > 2)
```  

### Forecast with loess

```{r loess prediction}
predict(mtcars_loess, data.frame(wt = 2))
```  

### loess forecast function

```{r loess prediction fucntion}
predict_cars_loess <- function(x){
  predict(mtcars_loess, data.frame(wt = x))
}

predict_cars_loess(5)
```

## Comparison of linear model and loess model for different car weights

```{r light cars}
predict_cars_lm(2)
predict_cars_loess(2)
```

```{r medium weight cars}
predict_cars_lm(3)
predict_cars_loess(3)
```  

```{r heavy cars}
predict_cars_lm(5)
predict_cars_loess(5)
```  