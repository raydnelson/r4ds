---
title: "Formulas and Model Families: Diamonds"
author: "MPA 634: Data Science for Managers"
date: "25 November 2019"
output: 
  html_document:
    code_folding: "hide"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load libraries
library(tidyverse)
library(modelr)
```  

### These four functions will help us focus on linear models rather than the R code which might distract us from learning about:  

*  Analysis of Variance (ANOVA)
*  Analysis of Covariance

```{r basic function definitions}
## Violin plot
violin_plot <- function(data_set, x, y) {
  x <- data_set[[x]]
  y <- data_set[[y]]
  tibble(x = x, y = y) %>%
    ggplot(aes(reorder(x, y, FUN = median), y)) +
    geom_violin(fill = "lightgreen") +
    geom_boxplot(width = 0.10, fill = "lightblue") +
    labs(title = "Violin Plot",
         x = "Categorical Explanatory Variable",
         y = "Response Variable")
}

## Relationship between response and explanatory
relationship <- function(data_set, x, y) {
  data_set %>%
    ggplot(aes_string(x, y)) +
    geom_point() +
    geom_smooth(method = "lm") +
    geom_smooth(colour = "red") +
    labs(title = "Relationship between response and explanatory variables",
         x = "Explanatory Variable",
         y = "Response Variable")
}

## main effects
graph_main_effects <- function(data_set, model, x, y) {
  data_set %>% 
    add_predictions(model = model, var = "pred") %>% 
    ggplot(aes_string(x = x, y = y, color = x)) +
    geom_point(show.legend = FALSE, position = "jitter") +
    geom_point(aes(y = pred), show.legend = FALSE, size = 5,
               color = "black", shape = 3,) +
    labs(
      title = "Visualization of different models.",
      x = "Explanatory Variable",
      y = "Response Variable"
    )
}

## Analysis of covariance
graph_predictions <- function(data_set, model, x, y, category) {
  data_set %>% 
    add_predictions(model = model, var = "pred") %>% 
    ggplot(aes_string(x = x, y = y, color = category)) +
    geom_point() +
    geom_line(aes(y = pred)) +
    labs(
      title = "Visualization of different models.",
      x = "Explanatory Variable",
      y = "Response Variable"
    )
}

```

### Select a subset of observations from the diamonds data frame.
```{r subset of diamonds}
## Select a subset of the diamonds by taking a random sample of 1000
data(diamonds)
diamonds_subset <- diamonds %>% sample_n(1000)
diamonds_subset %>% glimpse()
```

### As considered previously, we want to consider the relationship between the price of diamonds and their cut. We can begin this exploration by using a violin plot.  

```{r differences in hwy mileage by type of drive train}
violin_plot(diamonds_subset, "cut", "price")
```

### Once again, an analysis of variance model lets us predict the price of a diamond given the category of its cut. This gives us a difference in means (intercepts). Since we don't have a numerical variable in the model, we have no slope terms in the model.  

```{r anova model}
zero_slope <- lm(price ~ cut, data = diamonds_subset)
zero_slope %>%  summary()
graph_main_effects(diamonds_subset, zero_slope, "cut", "price")
```

### Is there a simple linear relationship between diamond price and weight measured in carats? If so, then we have a good start on creating a model that will help us predict price conditional on weight.  

```{r simple linear relationship}
relationship(diamonds_subset, "carat", "price")
```

### It is possible to have a common slope for displacement and different intercepts based on the type of drive train of vehicle. This is one version of an analysis of covariance model.  

```{r different intercepts but a common slope}
common_slope <- lm(price ~ carat + cut, data = diamonds_subset)
common_slope %>% summary()
graph_predictions(diamonds_subset, common_slope, "carat", "price", "cut")
```

### An analysis of covariance model also allows us to simultaneously have both categorical and numerical variables as predictors. If we include an interaction term, then each category can have a different slope and intercept.

```{r different slopes and intercepts}
different_slopes <- lm(price ~ carat + cut + carat * cut, data = diamonds_subset)
different_slopes %>% summary()
graph_predictions(diamonds_subset, different_slopes, "carat", "price", "cut")
```

### We can now use the different_slopes model to predict the price of diamonds.

```{r predicting a diamonds price}
different_slopes %>% 
  predict(newdata = tibble(carat = c(0.5, 1.0), cut = c("Ideal", "Good")))
```