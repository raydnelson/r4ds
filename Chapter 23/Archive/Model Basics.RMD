---
title: "Model Basics"
author: "Ray Nelson"
date: "26 March 2019"
output: 
  html_document:
    code_folding: "hide"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load libraries
library(tidyverse)
library(conflicted)
conflict_prefer("filter", "dplyr")
conflict_prefer("lag", "dplyr")
library(forecast)
library(fImport)
library(Quandl)
library(timeSeries)
library(car)
library(magrittr)
```  

This R Markdown document requires the forecast, fImport, Quandl, timeSeries, car, and magrittr libraries. For this reason, you may need to install them in order for you to be able to execute the code.  

## Models

*  Extract patterns from data
*  Decompose variation into explained and unexplained
*  Attempt to extract all possible information from data
*  Achieve balance between explanatory power and simplicity  


## Patterns and models (From Chapter 7.6)

> Could this pattern be due to coincidence (i.e. random chance)?

> *  How can you describe the relationship implied by the pattern
> *  How strong is the relationship implied by the pattern?
> *  What other variables might affect the relationship?
> *  Does the relationship change if you look at individual subgroups of the data?  

## mtcars: A Simple Regression  

We would like to be able to predict a car's mileage based on its weight.  

### Start with a graph of the data  

```{r graph of mpg on weight}
mtcars %>% 
  ggplot(aes(wt, mpg)) +
  geom_point() +
  geom_smooth(method = "lm") +
  geom_smooth(color = "red")
```  

### Estimate a simple regression equation  

```{r simple regression estimation}
mtcars_lm <- lm(mpg ~ wt, data = mtcars)
mtcars_lm %>% str()
mtcars_lm %>% coefficients()
mtcars_lm %>% residuals()
mtcars_lm %>% fitted()
```  

### How good is the model?

```{r simple regression model evaluation}
## How good is the model
mtcars_lm %>%
  summary()
mtcars_lm %>% 
  plot()
mtcars_lm %>% 
  residualPlots()
```  

### Linear model predictions  

```{r mtcars predictions}
## Prediction with the linear model
mtcars_lm %>%
  predict(newdata = tibble(wt = 2))
```  


#### Function to predict

```{r function to make predictions}
predict_cars_lm <- function(x){
  mtcars_lm %>% predict(newdata = data.frame(wt = x))
}

predict_cars_lm(5)
mtcars$wt %>% range()
```

## loess model to handle the nonlinear relationship

loess is also known as local regression and is related to the family of generalized additive models

```{r loess model}
mtcars_loess <- loess(mpg ~ wt, data = mtcars)
mtcars_loess %>% str()
```  

### How good is the model?

```{r evaluation of loess model, message = FALSE}
mtcars_loess %>% summary()

fitted_values <- mtcars_loess %>%
  fitted()
studentized_resiudals <- mtcars_loess %>%
  residuals() %>% 
  scale()

tibble(fitted_values, studentized_resiudals) %>% 
  ggplot(aes(fitted_values, studentized_resiudals)) +
  geom_point() +
  geom_smooth()
```  

### Forecast with loess

```{r loess prediction}
predict(mtcars_loess, data.frame(wt = 2))
```  

### loess forecast function

```{r loess prediction fucntion}
predict_cars_loess <- function(x){
  predict(mtcars_loess, data.frame(wt = x))
}

predict_cars_loess(5)
```

## Comparison of linear model and loess model for different car weights

```{r light cars}
predict_cars_lm(2)
predict_cars_loess(2)
```

```{r medium weight cars}
predict_cars_lm(3)
predict_cars_loess(3)
```  

```{r heavy cars}
predict_cars_lm(5)
predict_cars_loess(5)
```

## Forecast of not seasonally adjusted retail sales  

### Obtain the data from FRED (Federal Reserve Economic Data Site at St. Louis Fed)

```{r get retail from FRED}
retail <- fredSeries("RSAFSNA", from = "1992-01-01") %>% 
  as.ts() %>%
  divide_by(1000)
```

### Draw a picture of the data  

```{r preliminary evaluation}
retail %>% 
  ggtsdisplay()
```

### Use the additive decomposition model to decompose the time series into:

*  Trend\Cycle
*  Seasonality
*  Remainder  

```{r stl decomposition}
retail_stl <- retail %>% 
  stl(s.window = 7)
retail_stl %>%
  str()
```

### Result of the decomposition  

```{r stl components}
retail_stl %>% 
  autoplot() +
  labs(
    title = "STL decomposition of time series"
  )
```

### Is there any information in the remainder?

```{r information in the remainder}
retail_stl$time.series[, "remainder"] %>% 
  ggtsdisplay() +
  labs(
    title = "There is still information in the remainder from STL"
  )
```

### Prediction using the STL model

```{r stl prediction}
retail_stl %>%
  forecast(h = 12) %>% 
  autoplot()
```

### ETS are part of the family of state space models and are also known as exponential smoothing  

```{r estimate an ets model}
retail_ets <- retail %>%
  ets(model = "ZZZ")
retail_ets %>% str()
retail_ets %>% summary()
retail_ets %>% residuals()
retail_ets %>% fitted() 
```  

### ETS doesn't extract all of the information from the data. Information remains in the residuals  

```{r information in ets residuals}
retail_ets %>% 
  residuals() %>% 
  ggtsdisplay()
```

### Forecasting with the ETS model

```{r ets forecasts}
retail_ets %>% 
  forecast(h = 12) %>% 
  autoplot()
```

### ARIMA is a family of models. ARIMA means auto-regressive, integrated, moving average.  

```{r estimate the ARIMA model}
retail_arima <- retail %>% 
  auto.arima()
retail_arima %>% str()
retail_arima %>% summary()
```

### ARIMA models seem to capture the more of the information than the other techniques 

```{r evaluation of ARIMA}
retail_arima %>% 
  residuals() %>% 
  ggtsdisplay()
```

### Forecasts from the ARIMA model

```{r arima forecasts}
retail_arima %>% 
  forecast(h = 12) %>%
  autoplot()
```














