---
title: "Formulas and Model Families: MPG"
author: "Ray Nelson"
date: "29 March 2019"
output: 
  html_document:
    code_folding: "hide"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
# Load libraries
library(tidyverse)
library(modelr)
```  

## Models

*  Extract patterns from data
*  Decompose variation into explained and unexplained
*  Extract all possible information from data
*  Achieve balance between explanatory power and simplicity  

## Four functions will help us understand the subfamilies of linear models called:  

*  Analysis of Variance (ANOVA)
*  Analysis of Covariance

```{r basic function definitions}
## Violin plot
violin_plot <- function(data_set, x, y) {
  x <- data_set[[x]]
  y <- data_set[[y]]
  tibble(x = x, y = y) %>%
    ggplot(aes(reorder(x, y, FUN = median), y)) +
    geom_violin(fill = "lightgreen") +
    geom_boxplot(width = 0.10, fill = "lightblue") +
    labs(title = "Violin Plot",
         x = "Categorical Explanatory Variable",
         y = "Response Variable")
}

## Relationship between response and explanatory
relationship <- function(data_set, x, y) {
  data_set %>%
    ggplot(aes_string(x, y)) +
    geom_point() +
    geom_smooth(method = "lm") +
    geom_smooth(colour = "red") +
    labs(title = "Relationship between response and explanatory variables",
         x = "Explanatory Variable",
         y = "Response Variable")
}

## main effects
graph_main_effects <- function(data_set, model, x, y) {
  data_set %>% 
    add_predictions(model = model, var = "pred") %>% 
    ggplot(aes_string(x = x, y = y, color = x)) +
    geom_point(show.legend = FALSE, position = "jitter") +
    geom_point(aes(y = pred), show.legend = FALSE, size = 5,
               color = "black", shape = 3,) +
    labs(
      title = "Visualization of different models.",
      x = "Explanatory Variable",
      y = "Response Variable"
    )
}

## Analysis of covariance
graph_predictions <- function(data_set, model, x, y, category) {
  data_set %>% 
    add_predictions(model = model, var = "pred") %>% 
    ggplot(aes_string(x = x, y = y, color = category)) +
    geom_point() +
    geom_line(aes(y = pred)) +
    labs(
      title = "Visualization of different models.",
      x = "Explanatory Variable",
      y = "Response Variable"
    )
}

```

### MPG Data Set
```{r review of data set}
mpg %>% glimpse()
```

### Investigating differences in hwy mileage conditioned on the type of drive train of the vehicle gives us a good start as we assess the potential value of including categorical variables in our linear model.

```{r differences in hwy mileage by type of drive train}
violin_plot(mpg, "drv", "hwy")
```

### We can estimate a simple model with drive train as a predictor of highway miles per gallon. This is equivalent to an analysis of variance (ANOVA). We have a categorical predictor variable and no numerical predictor variables. The means that we have intercept terms in our regression equation and no slopes.

```{r anova model}
zero_slope <- lm(hwy ~ drv, data = mpg)
zero_slope %>% summary()
graph_main_effects(mpg, zero_slope, "drv", "hwy")
```

### Is there a simple linear relationship between highway mileage and engine displacement? If so, then we have a good start on creating a model that will help us predict mpg conditional on engine displacement.  

```{r simple linear relationship}
relationship(mpg, "displ", "hwy")
```

### It is possible to have a common slope for displacement and different intercepts based on the type of drive train of vehicle. This is one version of an analysis of covariance model.  

```{r different intercepts but a common slope}
common_slope <- lm(hwy ~ displ + drv, data = mpg)
common_slope %>% summary()
graph_predictions(mpg, common_slope, "displ", "hwy", "drv")
```

### An analysis of covariance model also allows us to have both categorical and numerical variables as predictors. If we include an interaction term, then each category can have a different slope and intercept.

```{r different slopes and intercepts}
different_slopes <- lm(hwy ~ displ + drv + displ * drv, data = mpg)
different_slopes %>% summary()
graph_predictions(mpg, different_slopes, "displ", "hwy", "drv")
```

### We can now use the different_slopes model to predict the mileage of a car:

```{r predict mileage}
different_slopes %>% 
  predict(newdata = tibble(displ = c(2, 3.5), drv = c("4", "f")))
```

